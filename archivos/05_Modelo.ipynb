{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Desarrollo Notebook 5*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-learn tabulate lightgbm xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importar librerías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Carga y lectura de dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('/Users/miguelflores/Desktop/datos/X_resampled.csv')\n",
    "X_test = pd.read_csv('/Users/miguelflores/Desktop/datos/X_test_1.csv')\n",
    "\n",
    "y_train = pd.read_csv('/Users/miguelflores/Desktop/datos/y_resampled.csv')\n",
    "y_test = pd.read_csv('/Users/miguelflores/Desktop/datos/y_test_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=['SK_ID_CURR'])\n",
    "X_test = X_test.drop(columns=['SK_ID_CURR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train['0'].values  # Selecciona la columna con las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de y_train: (39720,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Forma de y_train:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1], shape=(39720,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 200, 300],\n",
    "    'classifier__max_depth': [3, 5, 7, 10],\n",
    "    'classifier__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'classifier__num_leaves': [20, 31, 40],\n",
    "    'classifier__subsample': [0.6, 0.8, 1.0],\n",
    "    'classifier__colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear pipeline\n",
    "pipe = Pipeline(steps = [('classifier', LGBMClassifier(is_unbalanced = True, random_state = seed))])\n",
    "\n",
    "# Configurar búsqueda de hiperparámetros\n",
    "modelo_optimo = RandomizedSearchCV(\n",
    "    pipe, \n",
    "    param_distributions = param_grid, \n",
    "    n_iter = 60,  # Número de combinaciones a probar\n",
    "    scoring = 'recall',  # Métrica de evaluación\n",
    "    cv = 5,  # Número de particiones para validación cruzada\n",
    "    random_state = seed,\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "# Entrenar\n",
    "modelo_optimo.fit(X_train, y_train)\n",
    "\n",
    "# Resultados\n",
    "print(\"Mejores parámetros:\", modelo_optimo.best_params_)\n",
    "print(\"Mejor puntuación:\", modelo_optimo.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inicialmente para encontrar el modelo más óptimo, es fundamental establecer un diccionario de hiperparámetros. Donde posteriormente un código configura y ejecuta una búsqueda aleatoria de hiperparámetros para un modelo LGBMClassifier dentro de un pipeline utilizando RandomizedSearchCV. Esto permite encontrar el mejor conjunto de parámetros para optimizar el modelo basado en la métrica recall. Al final, imprime los mejores parámetros y la mejor puntuación obtenida.\n",
    "\n",
    "#### Este enfoque de optimización de hiperparámetros ayuda a mejorar el rendimiento del modelo sin tener que probar manualmente todas las combinaciones posibles, lo que es más eficiente cuando se tienen muchos parámetros. Posteriormente de esto podemos guardar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado como modelo_entrenado.pkl\n"
     ]
    }
   ],
   "source": [
    "# Importar librería para serializar el documento\n",
    "import pickle\n",
    "\n",
    "# Determinar la ruta donde se generara el archivo y el formato deseado en este caso binario 'wb'\n",
    "with open('/Users/miguelflores/Desktop/PracticaDocker/modelo_entrenado.pkl', 'wb') as f:\n",
    "    # Serializa el modelo\n",
    "    pickle.dump(modelo_optimo.best_estimator_, f)\n",
    "\n",
    "# Confirmar la acción\n",
    "print('Modelo guardado como modelo_entrenado.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Env_Pd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
